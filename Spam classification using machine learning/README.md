
![image](https://user-images.githubusercontent.com/121180975/209113479-b398eb7e-9839-4da5-b96f-45c948f0170f.png)


Approach Loading Data

1.Input and Output Data

2.Applying Regular Expression

3.Each word to lower case

4.Splitting words to Tokenize

5.Stemming with PorterStemmer handling Stop Words

6.Preparing Messages with Remaining Tokens

7.Preparing WordVector Corpus

Applying Classification

Models :

Multinomial naive bayes

Random Forest
